{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup  # Check description below if not already installed\n",
    "import seaborn as sns\n",
    "\n",
    "%pylab inline\n",
    "\n",
    "sns.set_palette('Set2', 8)\n",
    "sns.set_context(\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Description\n",
    "\n",
    "## Background\n",
    "In this homework we will extract interesting information from www.topuniversities.com and www.timeshighereducation.com, two platforms that maintain a global ranking of worldwide universities. This ranking is not offered as a downloadable dataset, so you will have to find a way to scrape the information we need!\n",
    "You are not allowed to download manually the entire ranking -- rather you have to understand how the server loads it in your browser. For this task, Postman with the Interceptor extension can help you greatly. We recommend that you watch this [brief tutorial](https://www.youtube.com/watch?v=jBjXVrS8nXs&list=PLM-7VG-sgbtD8qBnGeQM5nvlpqB_ktaLZ&autoplay=1) to understand quickly how to use it.\n",
    "\n",
    "## Assignment\n",
    "1. Obtain the 200 top-ranking universities in www.topuniversities.com ([ranking 2018](https://www.topuniversities.com/university-rankings/world-university-rankings/2018)). In particular, extract the following fields for each university: `name`, `rank`, `country` and `region`, `number of faculty members` (international and total) and `number of students` (international and total). Some information is not available in the main list and you have to find them in the [details page](https://www.topuniversities.com/universities/ecole-polytechnique-fédérale-de-lausanne-epfl).\n",
    "Store the resulting dataset in a pandas DataFrame and answer the following questions:\n",
    "- Which are the best universities in term of: (a) ratio between faculty members and students, (b) ratio of international students?\n",
    "- Answer the previous question aggregating the data by (c) country and (d) region.\n",
    "\n",
    "Plot your data using bar charts and describe briefly what you observed.\n",
    "\n",
    "2. Obtain the 200 top-ranking universities in www.timeshighereducation.com ([ranking 2018](http://timeshighereducation.com/world-university-rankings/2018/world-ranking)). Repeat the analysis of the previous point and discuss briefly what you observed.\n",
    "\n",
    "3. Merge the two DataFrames created in questions 1 and 2 using university names. Match universities' names as well as you can, and explain your strategy. Keep track of the original position in both rankings.\n",
    "\n",
    "4. Find useful insights in the data by performing an exploratory analysis. Can you find a strong correlation between any pair of variables in the dataset you just created? Example: when a university is strong in its international dimension, can you observe a consistency both for students and faculty members?\n",
    "\n",
    "5. Can you find the best university taking in consideration both rankings? Explain your approach.\n",
    "\n",
    "Hints:\n",
    "- Keep your Notebook clean and don't print the verbose output of the requests if this does not add useful information for the reader.\n",
    "- In case of tie, use the order defined in the webpage.\n",
    "\n",
    "## BeautifulSoup soup\n",
    "\n",
    "BeautifulSoup is used to extract tags and information from webpage. To install the package please use the following command\n",
    "\n",
    "```\n",
    "conda install beautifulsoup4\n",
    "```\n",
    "\n",
    "# 1. topuniversities.com\n",
    "\n",
    "Let's first focus on the first website. If you go to www.topuniversities.com ([ranking 2018](https://www.topuniversities.com/university-rankings/world-university-rankings/2018)) you will see the first 25 top ranked universities. Howerver if you look at the code source (HTML web page) you will not find occurence of MIT ranking informations. Let's now use Console (ctrl-shift-k on Firefox, ctrl-shift-i on Chrome). You can see the web trafic (Network on Firefox and Chrome), i.e. every requests that are sent the porperly display the webpage.\n",
    "\n",
    "\n",
    "We can see that most of them are css files (*.css), javascript files (*.js) or images (*.png). The website will load the images of each university, therfore we can assume that it needs to know what is the ranking to do so.\n",
    "\n",
    "## 1.1 Main ranking information\n",
    "If we look on the requests that append just before we can find a XHR files (XML Http Request) https://www.topuniversities.com/sites/default/files/qs-rankings-data/357051.txt. It contains the univertities names and attributes. If you click on the link you can see that it is a JSON file. The first level is a key named `data`. `data` is a vector and each element if a university with tags displayed below. We can keep `country`, `rank_display`, `score`, `title`, `region`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://www.topuniversities.com/sites/default/files/qs-rankings-data/357051.txt')\n",
    "print('Tags of JSON 1st level: {}'.format(r.json().keys()))\n",
    "print('Tags of JSON 2nd level: {}'.format(r.json()['data'][0].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_uni_df = pd.DataFrame(r.json()['data'], columns=['title', 'country', 'region', 'rank_display', 'score', 'url'])\n",
    "top_uni_df.iloc[25:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that some univertities have same rank. In this case the rank number will be `= X` where `X` is the ranking number. We cannot only cast it to integer we have to remove `=` first. We also complete the url for each university with `url` = `https://www.topuniversities.com` + `url` + `#wurs` according to href link of website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_uni_df['score'] = pd.to_numeric(top_uni_df['score'], errors='coerce')\n",
    "top_uni_df['rank_display'] = pd.to_numeric(top_uni_df['rank_display'].map(lambda x: x.lstrip('=')), errors='coerce')\n",
    "top_uni_df['url'] = top_uni_df['url'].map(lambda x: 'https://www.topuniversities.com' + x + '#wurs')\n",
    "top_uni_df = top_uni_df.sort_values(by='score', ascending=False).iloc[:200]\n",
    "top_uni_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform a sanity check. We can see that there are no NaN values in our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(top_uni_df.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Unversities detailed informations\n",
    "\n",
    "We still need to find `number of faculty members` (international and total) and `number of students` (international and total). To do so we will use the `url` field that contains the URL to the page that describe the university. If we look, for example, at the [MIT](https://www.topuniversities.com/universities/massachusetts-institute-technology-mit#wurs) one we can see that there are plots displaying the Number of academic faculty staff aka `number of faculty members` and `number of students`. \n",
    "\n",
    "Looking at the source code allow us to see that thoses values are hard coded in the web page. We can therefore use BS4 to directly get the infos. All values are located inside `<div>` tags and have `class='number'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from log import log_progress  # Fancy progress display\n",
    "# Will contain the university info as [faculty_total, faculty_international, student_total, student_international]\n",
    "infos = np.ones((len(top_uni_df), 4))*np.nan  \n",
    "for i, url in log_progress(enumerate(top_uni_df['url']), every=1, size=len(top_uni_df)): \n",
    "    try:\n",
    "        # Get request for specific university\n",
    "        r_uni = requests.get(url)\n",
    "        soup = BeautifulSoup(r_uni.text, 'html.parser')\n",
    "        # Parse file to get specific informations about faculty and stuent (according to website html structure)\n",
    "        faculty = soup.find('div', class_='faculty-main')\n",
    "        infos[i, 0:2] = [int(val.text.replace(',', '')) for val in faculty.find_all('div', class_='number')]\n",
    "        infos[i, 2] = int(soup.find('div', class_='students-main').find('div', class_='number').text.replace(',', ''))\n",
    "        infos[i, 3] = int(soup.find('div', class_='int-students-main').find('div', class_='number').text.replace(',', ''))\n",
    "    except Exception as e:\n",
    "        print('Unable to find fields:', url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the requests are performed and values loaded we can affect them to their respective fields. Note that (New York University)[https://www.topuniversities.com/universities/new-york-university-nyu#wurs] does not have informatation about student and facultier memebers. Therefore the values will be set to NaN. We also save the results avoid performing crowling at each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_uni_df['faculty_tot'] = infos[:, 0]\n",
    "top_uni_df['faculty_int'] = infos[:, 1]\n",
    "top_uni_df['student_tot'] = infos[:, 2]\n",
    "top_uni_df['student_int'] = infos[:, 3]\n",
    "top_uni_df.set_index(['title'], inplace=True)\n",
    "top_uni_df.to_csv('top_uni.csv')  # Backup (just run fetch once)\n",
    "top_uni_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check if our index `title` is unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Is index unique: {}'.format(top_uni_df.index.is_unique))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Results \n",
    "\n",
    "We can load our csv file and set `title` as index column. It allows us to check if all entries are unique (should be the case of course)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) - (b)\n",
    "\n",
    "We dont have to create new fields. All values are already present in our dataframe. We therefore express. (a) ratio between faculty members and students as `faculty_tot`/`student_tot` and (b) ratio of international students as `student_int`/`student_tot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import wrap\n",
    "N_TOP = 8\n",
    "def nice_bar_plot(data, ax, title='', y_axis=''):\n",
    "    ax.set_title(title , fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel(y_axis)\n",
    "    labels = [ '\\n'.join(wrap(l, 15)) for l in data.index ]\n",
    "    g = sns.barplot(x=labels, y=data.values,  ax=ax)\n",
    "    [lab.set_rotation(45) for lab in ax.get_xticklabels()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16,6))\n",
    "# Ratio faculty_tot / student_tot\n",
    "fac_vs_stu = top_uni_df['faculty_tot'].div(top_uni_df['student_tot']).sort_values(ascending=False).iloc[:N_TOP]\n",
    "nice_bar_plot(fac_vs_stu, title='Ratio faculty members vs Students', y_axis='ratio', ax=axes[0])\n",
    "# Ratio student_int / student_tot\n",
    "stu_vs_int = top_uni_df['student_int'].div(top_uni_df['student_tot']).sort_values(ascending=False).iloc[:N_TOP]\n",
    "nice_bar_plot(stu_vs_int, title='Ratio International Students vs Total Students', y_axis='ratio', ax=axes[1])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) `Country`\n",
    "Same logic as before, except we need to group entries by `country`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16,6))\n",
    "# Ratio faculty_tot / student_tot (country)\n",
    "fac_vs_stu = top_uni_df.groupby('country')['faculty_tot'].sum().div(top_uni_df.groupby('country')['student_tot'].sum())\\\n",
    "                .sort_values(ascending=False).iloc[:N_TOP]\n",
    "nice_bar_plot(fac_vs_stu, title='Ratio faculty members vs Students (country)', y_axis='ratio', ax=axes[0])\n",
    "# Ratio student_int / student_tot\n",
    "stu_vs_int = top_uni_df.groupby('country')['student_int'].sum().div(top_uni_df.groupby('country')['student_tot'].sum())\\\n",
    "                .sort_values(ascending=False).iloc[:N_TOP]\n",
    "nice_bar_plot(stu_vs_int, title='Ratio International Students vs Total Students (country)', y_axis='ratio', ax=axes[1])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) `Region`\n",
    "\n",
    "Same logic as before, except we need to group entries by `region`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16,6))\n",
    "# Ratio faculty_tot / student_tot (country)\n",
    "fac_vs_stu = top_uni_df.groupby('region')['faculty_tot'].sum().div(top_uni_df.groupby('region')['student_tot'].sum())\\\n",
    "                .sort_values(ascending=False).iloc[:N_TOP]\n",
    "nice_bar_plot(fac_vs_stu, title='Ratio faculty members vs Students (region)', y_axis='ratio', ax=axes[0])\n",
    "# Ratio student_int / student_tot\n",
    "stu_vs_int = top_uni_df.groupby('region')['student_int'].sum().div(top_uni_df.groupby('region')['student_tot'].sum())\\\n",
    "                .sort_values(ascending=False).iloc[:N_TOP]\n",
    "nice_bar_plot(stu_vs_int, title='Ratio International Students vs Total Students (region)', y_axis='ratio', ax=axes[1])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. timeshighereducation.com\n",
    "\n",
    "We can now look at the second website : https://www.timeshighereducation.com. On the ([ranking 2018](https://www.timeshighereducation.com/world-university-rankings/2018/world-ranking#!/page/0/length/25/sort_by/rank/sort_order/asc/cols/stats)) page we can also see the first 25 ranked universities. By inspecting the source code of the webpage you can see that the informations we want to retrieve are not hard coded but are fetch from other links - same as for the first website. \n",
    "\n",
    "### 2.1 Main ranking information\n",
    "\n",
    "We used the same approach as for the top-university website and used the console to see the requests sent by the page when it loads. We could identify a [link](https://www.timeshighereducation.com/sites/default/files/the_data_rankings/world_university_rankings_2018_limit0_369a9045a203e176392b9fb8f8c1cb2a.json) to a JSON file. <br>\n",
    "While inspecting this file, we could find 4 first level key, especially one called `data` containing the tags related to what we are looking for, i.e. `name`, `location`, `rank`, `stats_number_students`. We found also that we could retrieve the student-staff ratio, `stats_student_staff_ratio`, which will be use to compute the number of faculty members later one. There is also the percentage of international student, `stats_pc_intl_students`, that we can use to compute the number of international students. We decided to keep the score, `scores_overall`, from each university as we think it can be useful for the second part of the exercise.\n",
    "\n",
    "We then proceed to store all those data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.timeshighereducation.com/sites/default/files/the_data_rankings/world_university_rankings_2018_limit0_369a9045a203e176392b9fb8f8c1cb2a.json'\n",
    "r = requests.get(URL)\n",
    "print('Tags of JSON 1st level: {}'.format(r.json().keys()))\n",
    "print('Tags of JSON 2nd level: {}'.format(r.json()['data'][0].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_df = pd.DataFrame(r.json()['data'], columns=['name', 'location', 'rank', 'scores_overall', 'stats_number_students', 'stats_pc_intl_students', 'stats_student_staff_ratio'])\n",
    "the_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Clean the Data\n",
    "\n",
    "We have extracted raw data from the JSON file, now we would like to perform some computation on certain columns to have matching data with the other website. To do so we will convert the column `stats_number_students`,  `stats_pc_intl_students` and `stats_student_staff_ratio` to numerical values, then we will perform the computation to get `student_int`, the number of international students and `faculty_tot`, the number of faculty members. We also get rid of the \"=\" in the `rank` column that meant an equality rank for two or more universities.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_df['scores_overall'] = pd.to_numeric(the_df['scores_overall'], errors='coerce')\n",
    "the_df['rank'] = pd.to_numeric(the_df['rank'].map(lambda x: x.lstrip('=')), errors='coerce')\n",
    "the_df['stats_pc_intl_students'] = pd.to_numeric(the_df['stats_pc_intl_students'].map(lambda x: x.rstrip('%')), errors='coerce')\n",
    "the_df['stats_number_students'] = pd.to_numeric(the_df['stats_number_students'].str.replace(',', ''), errors='coerce')\n",
    "the_df['stats_student_staff_ratio'] = pd.to_numeric(the_df['stats_student_staff_ratio'], errors='coerce')\n",
    "# Find number of Intl Student from % and total nber student after cleaning\n",
    "the_df['student_int'] = (the_df['stats_pc_intl_students'] * the_df['stats_number_students'] / 100).round().astype(int)\n",
    "the_df['faculty_tot'] = (the_df['stats_number_students'] / the_df['stats_student_staff_ratio']).round().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have matching data regarding to the dataframe generated from top-university website, we can drop the columns `stats_pc_intl_students` and `stats_student_staff_ratio` that are no longer required. After that we rename the columns we keep in order that their names match the names from the top-university dataframe to ease the merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_df.drop(['stats_pc_intl_students', 'stats_student_staff_ratio'], axis=1, inplace=True)\n",
    "the_df.columns = ['title', 'country', 'rank_display', 'score', 'student_tot', 'student_int', 'faculty_tot']\n",
    "the_df = the_df.sort_values(by='score', ascending=False).iloc[:200]\n",
    "the_df.set_index(['title'], inplace=True)\n",
    "the_df.to_csv('the.csv')\n",
    "the_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(the_df.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check if our index `title` is unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Is index unique: {}'.format(the_df.index.is_unique))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) - (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16,6))\n",
    "# Ratio faculty_tot / student_tot\n",
    "fac_vs_stu = the_df['faculty_tot'].div(the_df['student_tot']).sort_values(ascending=False).iloc[:N_TOP]\n",
    "nice_bar_plot(fac_vs_stu, title='Ratio faculty members vs Students', y_axis='ratio', ax=axes[0])\n",
    "# Ratio student_int / student_tot\n",
    "stu_vs_int = the_df['student_int'].div(the_df['student_tot']).sort_values(ascending=False).iloc[:N_TOP]\n",
    "nice_bar_plot(stu_vs_int, title='Ratio International Students vs Total Students', y_axis='ratio', ax=axes[1])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) `Country`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16,6))\n",
    "# Ratio faculty_tot / student_tot (country)\n",
    "fac_vs_stu = the_df.groupby('country')['faculty_tot'].sum().div(the_df.groupby('country')['student_tot'].sum())\\\n",
    "                .sort_values(ascending=False).iloc[:N_TOP]\n",
    "nice_bar_plot(fac_vs_stu, title='Ratio faculty members vs Students (country)', y_axis='ratio', ax=axes[0])\n",
    "# Ratio student_int / student_tot\n",
    "stu_vs_int = the_df.groupby('country')['student_int'].sum().div(the_df.groupby('country')['student_tot'].sum())\\\n",
    "                .sort_values(ascending=False).iloc[:N_TOP]\n",
    "nice_bar_plot(stu_vs_int, title='Ratio International Students vs Total Students (country)', y_axis='ratio', ax=axes[1])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) `Region`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A traiter --> il n'y a pas de region sur le Times Higher Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''fig, axes = plt.subplots(1, 2, figsize=(16,6))\n",
    "# Ratio faculty_tot / student_tot (country)\n",
    "fac_vs_stu = top_uni_df.groupby('region')['faculty_tot'].sum().div(top_uni_df.groupby('region')['student_tot'].sum())\\\n",
    "                .sort_values(ascending=False).iloc[:N_TOP]\n",
    "nice_bar_plot(fac_vs_stu, title='Ratio faculty members vs Students (region)', y_axis='ratio', ax=axes[0])\n",
    "# Ratio student_int / student_tot\n",
    "stu_vs_int = top_uni_df.groupby('region')['student_int'].sum().div(top_uni_df.groupby('region')['student_tot'].sum())\\\n",
    "                .sort_values(ascending=False).iloc[:N_TOP]\n",
    "nice_bar_plot(stu_vs_int, title='Ratio International Students vs Total Students (region)', y_axis='ratio', ax=axes[1])\n",
    "plt.tight_layout()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_df = pd.read_csv('the.csv', index_col='title')\n",
    "top_uni_df = pd.read_csv('top_uni.csv', index_col='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate((top_uni_df['country'].unique(), the_df['country'].unique()))\n",
    "name, count = np.unique(data, return_counts=True)\n",
    "print(name[count == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Russian university to compare:\\n\\t{}\\n\\t{}'.format(\n",
    "    the_df[the_df['country'] == 'Russian Federation'].index.values,\n",
    "    top_uni_df[top_uni_df['country'] == 'Russia'].index.values))\n",
    "\n",
    "the_df.loc[the_df['country'] == 'Russian Federation', 'country'] = 'Russia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop(name):\n",
    "    stops = ['university', 'of', 'the', 'technology', 'de', 'institute', \n",
    "             'Universität', 'Universitaet', 'zu', 'technical']\n",
    "    for stop in stops:\n",
    "        name= name.replace(stop, '')\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "data = []\n",
    "for country, the_country in the_df.groupby('country'):  # Iteration over sub datasets (country grouping)\n",
    "    top_uni_country = top_uni_df.loc[top_uni_df['country'] == country]  # Match only in same country\n",
    "    if len(top_uni_country) == 0:  # No country find in other dataset -> skip\n",
    "        continue\n",
    "    for name_the in the_country.index:   # Iteration our university name\n",
    "        score = np.zeros(len(top_uni_country.index))\n",
    "        for i, name_top in enumerate(top_uni_country.index):  # Compare with other data set entries\n",
    "            score[i] = SequenceMatcher(None, remove_stop(name_top.lower()), \n",
    "                                       remove_stop(name_the.lower())).ratio()\n",
    "        # Append best score\n",
    "        data.append([name_the, top_uni_country.index[np.argmax(score)], np.max(score), country])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datafram with scores, names and countries\n",
    "df = pd.DataFrame(data,  columns=['title_the', 'title_top', 'match_score', 'country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only values with 0.7 confidence\n",
    "df[df['match_score'] > 0.7].sort_values('match_score').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only values with 0.7 confidence\n",
    "df[df['match_score'] <= 0.70].sort_values('match_score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched = df[df['match_score'] > 0.70]\n",
    "duplicates = matched[matched.duplicated(subset='title_top')]['title_top']\n",
    "matched.set_index(['title_top']).loc[duplicates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched = matched.sort_values('match_score', ascending=False).drop_duplicates(subset='title_top')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionnary entries to replace old name with new one (same names to make merge easier)\n",
    "renamed_index = dict(zip(top_uni_df.loc[matched['title_top']].index.values, \n",
    "                         the_df.loc[matched['title_the']].index.values))\n",
    "top_uni_df.rename(index=renamed_index, inplace=True)\n",
    "# top_uni_df.loc[matched['title_the']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.merge(top_uni_df, the_df, right_index=True, left_index=True, \n",
    "                    how='inner', suffixes=('_top', '_times'))\n",
    "df_final.drop(['url', 'country_top', 'country_times', 'faculty_int'], axis=1, inplace=True)\n",
    "df_final['is_epfl'] = df_final.index == 'École Polytechnique Fédérale de Lausanne'\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Matched universities: {}'.format(len(df_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_times = pd.cut(df_final['rank_display_times'], [0, 5, 15, 50, 100, 200])\n",
    "print('Named matched for Times ranking:\\n{}'.format(df_final_times.value_counts(sort=False).cumsum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_times = pd.cut(df_final['rank_display_top'], [0, 5, 15, 50, 100, 200])\n",
    "\n",
    "print('Named matched for Top Universities ranking:\\n{}'.format(df_final_times.value_counts(sort=False).cumsum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Results and Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_final, hue='is_epfl',\n",
    "             x_vars=['rank_display_top', 'score_top', 'faculty_tot_top', 'student_tot_top', 'student_int_top'],\n",
    "             y_vars=['rank_display_times', 'score_times', 'faculty_tot_times', 'student_tot_times', 'student_int_times'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_final, hue='is_epfl',\n",
    "             y_vars=['score_top'],\n",
    "             x_vars=['faculty_tot_top', 'student_tot_top', 'student_int_top'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_final, hue='is_epfl',\n",
    "             y_vars=['score_times'],\n",
    "             x_vars=['faculty_tot_times', 'student_tot_times', 'student_int_times'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_final['score_mean'] = (df_final['score_times'] + df_final['score_top'])/2\n",
    "df_final.sort_values('score_mean', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TOP = 10\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16,4))\n",
    "df_europe = df_final.loc[df_final['region']=='Europe']\n",
    "nice_bar_plot(df_europe['score_mean'][:N_TOP], ax, title='Best European universities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
